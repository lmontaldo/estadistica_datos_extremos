\subsection{El enfoque de conteo de eventos y los modelos de base Poissoniana.} 

Fijaremos un cierto umbral, llamaremos \textit{evento} cuando la variable observada supera ese umbral y dado un cierto intervalo del tiempo $J$, contaremos

\begin{eqution}
N(J)= \text{número de eventos en el intervalo}\; J.
\end{equation}


Fijando un $u=1.025$, el evento es una señal negativa del precio de $SP\$500$ que estaría dado por la cantidad de días en el mes $J$ que $Indicador_t$ supera el umbral $u$.
Un evento ser que $Indicador_t$ supere un umbral $u>1.025$.  Si el número de eventos está dado por los días de un mes, entonces $N(mes)$ va a ser la cantidad de días que occurió el evento en un mes, $N(mes)=3$ es la cantidad de señales negativas en el mes.

como la cantidad de días ($d$) que el indicar aumentó un cierto porcentaje de $d-1$ a $d$.

$2.5\%$ en un
Si $d$ es la cantidad de días y $J$ es el intervalo de días en un mes, N(mes)
N(mes)= cantidad de períodos de 3 días durante un mes, en que se registró una aumento mayor o igual a 2.5% del índice de un día para el otro.


$N$ es lo que se llama un proceso de conteo o proceso puntua\footnote{\textit{Counting process, Point process} en inglés}, un tipo de modelos utilizados en Logística, Telecomunicaciones, estudios de Contaminación Atmosférica o Costera, Clima, etc.

El proceso de conteo más simple es el llamado \textit{Proceso de Poisson}, que puede caracterizarse de la siguiente manera.


 
\begin{definition}[Proceso de Poisson]\label{def:1}
Si $N$ es un proceso de conteo y $\lambda>0$, diremos que $N$ es un Proceso de Poisson de parámetro $\lambda$ (y abreviaremos $N$ es $PP(\lambda)$ ) si se cumple:
\begin{itemize}
\item[a)] Para todo intervalo $J$ de los reales positivos, $N(J)$ es una variable aleatoria que tiene distribución de Poisson de parámetro $\lambda$ longitud($J$).
\item[b)] Si $J, L, M...$ es una cantidad arbitraria de intervalos de reales positivos \textit{disjuntos}, entonces $N(J), N(L), N(M),...$ son variables aleatorias independientes.
\end{itemize}
\end{definition}

El siguiente teorema brinda una visualización muy interesante de los Procesos de Poisson, que nos servirá mucho para introducir otros modelos y que es ideal para poder simular computacionalmente Procesos de Poissson.

\begin{theorem}[Otra visión de los Procesos de Poisson]\label{thm:otra_vision}
Si $T_1,...,T_n,...$ se supone $iid$,  con distribución Exponencial de parámetro $\lambda>0$ y definimos que ocurre el primer evento en el instante $T_1$, el segundo en el instante $T_1+T_2$, el tercero en el instante $T_1+T_2+T_3$ y asì sucesivamente, el proceso $N$ de conteo de tales eventos, es un proceso de Poisson.
\end{theorem}




Dicho de otro modo el Proceso de Poisson representa eventos aislados ("que ocurren de a uno y claramente separados"), con tiempos inter-eventos $iid$ y exponenciales.
Obviamente, esto muchas veces es \textit{too good to be true}, pero variaciones de este modelo tan simple pueden brindar modelos realistas.


##### Observación 1: 

En la práctica, si se toman datos en los instantes $1,...,n$ suele reescalarse el tiempo dividiendo por $n$ y los instantes quedan en $[0,1]$. Allí se define un $PP$ de manera casi idéntica, obviamente modificando en la definición, tanto en $a)$ como en $b)$ que los intervalos deben estar contenidos en $[0,1]$.

##### Observación 2: 

Conviene recordar que si $X$ es una $VA$ Poisson de parámetro $\lambda>0$ y $T$ es una $VA$ exponencial de parámetro $\lambda$, entonces $E(X)= \lambda$ y $E(T)=1/lambda$ . Si $T_1,...,T_n,...$ siendo $iid$ son los tiempos inter-eventos de un $PP(\lambda)$ se deduce entonces de la ley de los grandes números que

\begin{equation}
\frac{\sum_{i=1}^{i=n} T_i}{n} \rightarrow 1/ \lambda \quad cuando \quad n\rightarrow \infty
\end{equation}

Es decir que el tiempo promedio entre eventos "a la larga" es $1/\lambda$ . Similarmente si $J_1,...,J_n,...$ son intervalos disjuntos de longitud $1$, por la definición \ref{def:1} y la ley de los grandes números se tiene que


\begin{equation}
\frac{\sum_{i=1}^{i=n} N(J_i)}{n} \rightarrow \lambda \quad cuando \quad n\rightarrow \infty
\end{equation}

Más aún, puede probarse que

\begin{equation}
\frac{N((0,t))}{t} \rightarrow \lambda \quad cuando \quad t \rightarrow \infty
\end{equation}

Esto permite observar una consecuencia del Teorema \ref{thm:otra_vision}, que es una propiedad intuitivamente muy atractiva.

La tasa promedial de incidencia de los eventos en un $PP(\lambda)$ es inversamente proporcional al tiempo promedial inter-eventos.

##### Ejemplo 1: 

Propiedades como esta hicieron, en las primeras dos décadas del siglo $XX$, a un creador genial como Agner Erlang modelar mediante Procesos de Poisson las llamadas que arribaban a una central telefónica, así como (con parámetros muy distintos) el proceso de ocupación de las líneas entre dos centrales. Eso condujo no sólo al desarrollo de las primeras centrales de telefonía conmutada por circuitos por CTC, la filial danesa de Bell, sino además a que Erlang desarrollara su "fórmulas de bloqueo", fino cálculo por el cual, según los parámetros del proceso de arribo y del proceso de ocupación de líneas, se calcula la probabilidad de "saturación" (no hay ninguna línea disponible) dado el número de líneas entre centrales, o, dada una probabilidad de saturación “tolerable” ($\epsilon$).

DISEÑAR (determinar el mínimo número de lineas necesarias para que la probabilidad de bloqueo no exceda $\epsilon$ ). Si el tiempo entre arribos de llamadas a la central es Exponencial de parámetro $\lambda$, y la duración media de una llamada es Exponencial de parámetro $\mu$, entonces el parámetro crucial de la fórmula de Erlang es 

\begin{align}
\rho=&\lambda/\mu  \nonumber \\
= &\text{“duración media de la llamada”/ “tiempo medio entre llamadas”}\label{eq:ro}
\end{align}


y a mayor valor de $\rho$, mayor probabilidad de saturación para una conectividad dada. Esta fórmula  \eqref{eq:ro} aún sigue en uso en algunos problemas y dió pie al desarrollo de fórmulas de bloqueo más sofisticadas para situaciones más complejas. Con mucha justicia, la unidad en la que se mide la intensidad de tráfico en redes se llama \textit{erlang} y este ejemplo nos parece una clara muestra de cuán útil ha sido el muy sencillo Proceso de Poisson.
Sin embargo, en otros problemas, por ejemplo en modernas redes de datos en las que los “eventos” de “demanda de servicio” pueden ocurrir simultáneamente en muy grandes cantidades (“clustering”), aparece un modelo más sofisticado, que puede ser definido a partir del Proceso de Poisson: el Proceso de Poisson Compuesto.


\begin{definition}[Proceso de Poisson Compuesto]\label{def:2}
Si $N$ es un Proceso de Poisson de parámetro $\lambda>0$ , $G$ es una distribución de probabilidad en los naturales $1,2,3...$, consideramos un proceso $S_1,...,S_n$ $iid$ con distribución $G$ y construímos un nuevo proceso de conteo $M$ de la forma siguiente:
\begin{itemize}
\item Cuando $N$ tiene su primer evento, $M$ tiene $S_1$ eventos simultáneos;
\item Cuando $N$ tiene su segundo evento, $M$ tiene $S_2$ eventos simultáneos..... (y así sucesivamente)
\end{itemize}
decimos que $M$ es un Proceso de Poisson Compuesto de parámetro $\lambda>0$ y distribución de eventos $G$ (y abreviaremos $M$ es $PPC(\lambda;G)$)
\end{definition}


##### Ejercicio 1 : 

Demostrar que para un $PPC(\lambda;G)$ el tiempo medio inter-eventos sigue siendo $1/\lambda$, pero que la tasa de incidencia media de eventos ahora es $lambda E(G)$.



##### Observación 3. 

Para aclarar, si $G$ es una distribución degenerada otorga al 1 probabilidad 1, el correspondiente $PPC(\lambda;G)$ en realidad es un $PPC(\lambda)$. Ergo, el $PP$ es un caso particular de $PPC$.

##### Observación 4. 

Para evitar confusiones frecuentes, distinguiremos explícitamente estos procesos de los llamados Procesos de Poisson no-homogéneos. Para ello recordemos, sin entrar en tecnicismos, que una medida en los reales positivos es una función que a los conjuntos asocia números positivos con las mismas propiedades formales, excepto que no tiene por qué dar a todo el conjunto de los reales positivos ( a todo el universo) el valor 1. Dicho de otro modo una probabilidad es una medida particular, que a todo el universo asigna el valor 1. Puede pensarse como ejemplo típico de una medida, la que asigna a un conjunto la integral sobre ese conjunto de una función no negativa (no necesariamente de integral total 1, puede ser incluso infinita). La longitud es el ejemplo más simple de medida (llamada también medida de Lebesgue) y la longitud de todos los reales positivos es infinito. Puede demostrarse que la longitud multiplicada por una constante no negativa son las únicas medidas invariantes por traslaciones, punto importante para la distinción que queremos hacer.

\begin{definition}[Proceso de Poisson No Homogéneo]\label{def:3}
Si $N$ es un proceso de conteo y $m$ es una medida que NO puede expresarse como una constante por la longitud, diremos que $N$ es un Proceso de Poisson No Homogéneo de medida $m$ (y abreviaremos $N$ es $PPNH(m)$ ) si se cumple:

\begin{itemize}
\item[a)] Para todo intervalo $J$ de los reales positivos, $N(J)$ es una variable aleatoria que tiene distribución de Poisson de parámetro $m(J)$.
\item[b)] Si $J, L, M...$ es una cantidad arbitraria de intervalos positivos DISJUNTOS, entonces $N(J), N(L), N(M),...$ son variables aleatorias independientes.
\end{itemize}
\end{definition}

Queda claro que el proceso de Poisson podría verse de la manera a) y b) anterior cuando $m=\text{constante por longitud}$, por eso, para no confundir, se excluye a título expreso que $m$ pueda ser constante por longitud.
Para dejar en claro la diferencia entre los PPNH y los PPC ( o el simple PP), recordemos que en los PPC, los tiempos inter-eventos son exponenciales de parámetro $\lambda>0$ e $iid$. El siguiente resultado muestra la diferencia de conceptos. Por su extrema simplicidad, lo detallaremos.


\begin{theorem}[PPNH no es PPC]\label{thm:2}
Si $N$ es un PPNH y $T_1$ es el tiempo del primer evento, la distribución de $T_1$ no es exponencial.
Por lo tanto, un PPNH no es PPC.
\end{theorem}

##### Demostración:

$$
P(T_1\le t)=P(N((0,t))\ge 1)=1-P(N((0,t))=0)= 1-e^{-m((0,t))}\quad\text{para todo}\; t>0.
$$


Si $T_1$ fuera exponencial, entonces para algún $\lambda>0$ y para todo $t>0$ sería:


$m((0,t))= \lambda t$ y por ende, si $a <b$ cualquiera,

$$m((a,b))= m((0,b))-m((0,a))=\lambda b- \lambda a= \lambda(b-a)=\lambda x\;longitud((a,b))$$ 

por lo cual se concluye, $m=\lambda x\:longitud$


lo cual es absurdo $\blacklozenge$.


<!-- ME QUEDE EN PAGINA 72 DEMOSTRACION Observación 5 -->
