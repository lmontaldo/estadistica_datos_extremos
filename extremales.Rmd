---
title: "Entrega: Curso De Datos Extremales"
author: "Laura Montaldo, CI: 3.512.962-7"
date: "`r Sys.Date()`"
bibliography: references.bib  # Add this line
csl: accident-analysis-and-prevention.csl
nocite: '@*'
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    includes:
      in_header: header2.tex
documentclass: article
classoption: 12pt
lang: es
---





```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
rm(list = ls())
```





```{r include=FALSE}
if (!require(lubridate)) {
    install.packages("lubridate")
}
library(lubridate)
if (!require(dplyr)) {
    install.packages("dplyr")
}
library(dplyr)
if (!require(ggplot2)) {
    install.packages("ggplot2")
}
library(ggplot2)
```
\newpage

<!-- titulo-->

\thispagestyle{empty}

\maketitle

\newpage

<!-- indice -->

\tableofcontents

\newpage

<!-- abstract -->

# Resumen

Your abstract goes here.

\newpage





```{r include=FALSE}
df = read.csv('data/sp500_Closing_values.csv')
```


```{r include=FALSE}
head(df)
```


```{r include=FALSE}
# Convert the column to datetime format
df$Date <- ymd_hms(df$Date)
# Extract just the date part
df$Date <- as.Date(df$Date)
```

```{r include=FALSE}
head(df)
```


```{r include=FALSE}
str(df)
```


```{r include=FALSE}
# Create a new column 'relacion' with yesterday's price over today's price
df <- df %>%
  mutate(relacion = lag(Close) / Close)
```


```{r include=FALSE}
head(df)
```

# Motivación y objetivo del estudio



Los índices de $S\&P$ son una familia de índices de renta variable\footnote{En inglés se llaman equity indices} diseñados para medir el rendimiento del mercado de acciones en Estados Unidos que cotizan en bolsas estadounidenses. Ésta familia de índices está compuesta por una amplia variedad de índices basados en tamaño, sector y estilo. Los índices están ponderados por el criterio \textit{float-adjusted market capitalization} (FMC). Además, se disponen de índices ponderados de manera equitativa y con límite de capitalización de mercado, como es el caso del $S\&P\:500$. Este este sentido, el $S\&P 500$ entraría en el conjunto de índices ponderados por capitalización bursátil ajustada a la flotación (ver \href{http://www.overleaf.com}{\textcolor{blue}{$S\&P$ Dow Jones Indices}}). El mismo  mide el rendimiento del segmento de gran capitalización del mercado estadounidense. Es considerado como un indicador representativo del mercado de renta variable de los Estados Unidos, y está compuesto por 500 empresas constituyentes.
 
Se busca crear un indicador de una posible crisis bursátil. Como variable de referencia de toma la relación de precios al cierre de ayer sobre la de hoy 

\begin{equation}
Indicador_t=\frac{Precio_{t-1}}{Precio_t},\quad\text{para}\; t=1,...,T \label{eq:ind}
\end{equation}
\vspace{0.5cm}

Interpretación del Indicador:

\begin{itemize}
\item Si el $Indicador_t$    $\leq$ 1, el precio de cierre de hoy es mayor o igual que el de ayer, lo cual podría ser considerado una señal positiva.
\item Si el $Indicador_t$ > 1, el precio de cierre de hoy es menor que el de ayer, lo cual podría considerarse una señal de alerta.
\end{itemize}

\vspace{1cm}

```{r include=FALSE}
# Remove the first row
df <- df[-1, ]
```


En las siguiente figura  \@ref(fig:plot1) se muestra la evolución histórica desde la fecha 03/01/1928 hasta 08/12/2023 del precio al cierre del día del indicar S&P 500.

```{r,echo=FALSE}
# Check for any NA or non-finite values in Date or Close
df <- na.omit(df)

# Determine the range of dates
date_range <- range(df$Date, na.rm = TRUE)
```

```{r,label='plot1',echo=FALSE}
# Your ggplot code
ggplot(df, aes(x = Date, y = Close)) +
  geom_line() +
  ggtitle("S&P500: valores diarios históricos al cierre (03/01/1928-08/12/2023)") +
  xlab("fecha") +
  ylab("Precio de cierre") +
  scale_x_date(limits = date_range) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11)  # Adjust the size parameter as needed
  )
```


```{r, label='plot2',echo=FALSE}
ggplot(df, aes(x = Date, y = relacion)) +
  geom_line() +
  ggtitle("S&P500: valores históricos del Indicador (03/01/1928-08/12/2023)") +
  xlab("fecha") +
  ylab("Valores del Indicador") +
  scale_x_date(limits = date_range) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11)  # Adjust the size parameter as needed
  )
```
\newpage

# Marco Teórico

## Teoría asintótica clásica y las distribuciones extremales y sus dominios de atracción

Siguiendo a @notas_curso
 se dice que tenemos datos extremos cuando cada
dato corresponde al máximo o mínimo de varios
registros. Son un caso particular de evento raro o gran 
desviación respecto a la media.

Asumiremos que nuestros datos son $iid$
(independientes e idénticamente distribuidos, son
dos suposiciones juntas). Esta doble suposición
suele no ser realista en aplicaciones concretas
(ninguna de sus dos componentes, incluso) pero
para comenzar a entender la teoría clásica, la
utilizaremos por un tiempo.

Si tenemos datos $X_1,...,X_n$ $iid$
con distribución $F$, entonces $X_n^* = max (X_1,...,X_n)$ tiene distribución $F_n^*$ dada por
$F_n^* (t)= F(t)_n$. Si conocemos la distribución $F$ conoceríamos la 
distribución $F_n^*$
, pero en algunos casos la lectura 
que queda registrada es la del dato máximo y no la 
de cada observación que dio lugar al mismo, por lo 
que a veces ni siquiera es viable estimar $F$.
Pero aún en los casos en que $F$ es conocida o 
estimable, si $n$ es grande, la fórmula de $F_n^*$ puede 
resultar prácticamente inmanejable. En una línea de trabajo similar a la que aporta el Teorema 
Central del Límite en la estadística de valores 
medios, un teorema nos va a permitir aproximar 
$F_n^*$ por distribuciones más sencillas. Este es el 
Teorema de Fischer-Tippet-Gnedenko (FTG, para 
abreviar) que presentaremos en breve.


Como $X_1,...,X_n$ iid, definimos 
$Y_i = -X_i$ para todo valor de $i$, entonces $Y_1,...,Y_n$ iid y
además
$min(X_1,...,X_n) = - max(Y_1,...,Y_n)$
la teoría asintótica de los mínimos de datos iid
se reduce a la de los máximos, razón por la que 
nos concentramos aquí en estudiar el 
comportamiento asintótico de los máximos 
exclusivamente.

\newpage

### Definición 1: Las distribuciones extremales

Las distribuciones extremales son tres: la
distribución de Gumbel; la distribución de Weibull; 
la distribución de Fréchet.

#### Distribución de Gumbel

Se dice que una variable tiene distribución de 
Gumbel si su distribución es: 

$$ \Lambda(x) = exp\{-e^{-x}\} \quad\text{para todo}\; x \;\text{real} $$


#### Distribución de Weibull

Se dice que una variable tiene distribución de 
Weibull de orden $\alpha>0$ si su distribución es:

$$\Psi_{\alpha}(x)=\begin{cases}
exp{-(-x)^{\alpha}} & si\;x<0\\
1 & \text{en otro caso}
\end{cases}$$

#### Distribución de Fréchet

Se dice que una variable tiene distribución de 
Fréchet de orden $\alpha>0$ si su distribución es:

$$
\Phi_{\alpha}(x)=\begin{cases}
exp\{-x^{-\alpha}\} & si\;x>0\\
0 & \text{en otro caso}
\end{cases}
$$
\newpage

##### Teorema 1: Relaciones entre las versiones standard de las distribuciones extremales

$X$ tiene distribución $\Phi_{\alpha}(x)$ si y sólo si $(-1/X)$ tiene 
distribución $\Psi_{\alpha}(x)$ si y sólo si $log(X^{\alpha})$ tiene 
distribución $\Lambda$.


##### Teorema 2: Algunos datos de las distribuciones extremales
##### Parte 1
Si $X$ tiene distribución $\Lambda^{(\mu,\beta)}$ entonces tiene:

\begin{itemize}
  \item[a)] Valor esperado: $E(X) = \mu + \beta\gamma$, donde $\gamma$ es la constante de Euler-Mascheroni, cuyo valor aproximado es $0.5772156649$.
  \item[b)] Moda: $\mu$
  \item[c)] Mediana: $\mu - \beta \log(\log 2) \approx \mu - 0.36651 \beta$.
  \item[d)] Desviación estándar: $\beta \pi \sqrt{6} \approx 1.2825 \beta$.
  \item[e)] Si $X^+ = \max(X,0)$, entonces $E(X+k)$ es finito para todo valor de $k$ natural.
  \item[f)] Para simular computacionalmente $X$, se puede tomar $U$ uniforme en $(0,1)$ y hacer $X = \mu - \beta \log(-\log U)$.
\end{itemize}

#### Parte 2

Si $X$ tiene distribución $\Psi_{\alpha}^{(\mu,\beta)}$ entonces tiene: 

\begin{itemize}
  \item[a)] Valor esperado: $E(X) = \mu + \beta\Gamma(1+1/\alpha)$.
  \item[b)] Moda: $\mu$ si $\alpha\leq 1$ y $\mu-\beta\{(\alpha-1)/\alpha\}^{(1/\alpha)}$ si $\alpha>1$.
  \item[c)] Mediana: $\mu - \beta \log(2)^{(1/\alpha)}$.
  \item[d)] Desviación estándar: $\beta\{\Gamma(1+2/\alpha)-\Gamma(1+1/\alpha)^2\}^{1/2}$.
\end{itemize}

#### Parte 2

Si $X$ tiene una distribución $\Phi_{\alpha}^{(\mu, \beta)}$ entonces se tiene:

\begin{itemize}
  \item[a)] Valor esperado: $E(X) = \mu + \beta\Gamma(1-1/\alpha)$ si $\alpha > 1$, $\infty$ en caso contrario.
  \item[b)] Moda: $\mu + \beta\Gamma(1-1/\alpha)$ si $\alpha>1$.
  \item[c)] Mediana: $\mu + \beta \log(2)^{(-1/\alpha)}$.
  \item[d)] Desviación estándar: $\beta|\Gamma(1-2/\alpha)-\Gamma(1-1/\alpha)^2|$ si $\alpha>2$, $\infty$ si $1<\alpha \leq 2$.
\end{itemize}


\newpage

##### Teorema 3: Fischer-Tippet-Gnedenko (FTG)


Si $X_1,...,X_n\quad iid$ con distribución $F$ "continua", llamamos $F_n^*$ a la distribución de $max(X_1,...,X_n)$ y $n$ es grande, entonces existen $\mu$ real y $\beta>0$ tales que alguna de las siguientes tres afirmaciones es correcta:

\begin{itemize}
  \item[1)] $F_n^*$ se puede apromixar por la distribución de $\mu+\beta Y$ con $Y$ variable con distribución $\Lambda$.
  \item[2)] Existe $\alpha>0$ tal que $F_n^*$ se puede aproximar por la distribución de $\mu+\beta Y$ con $Y$ variable con distribución $\Phi_{\alpha}$. 
  \item[3)] Existe $\alpha>0$ tal que $F_n^*$ se puede aproximar por la distribución de $\mu+\beta Y$ con $Y$ variable con distribución $\Phi_{\alpha}$.
\end{itemize}

Lo anterior equivale a decir que la distribución del máximo de datos \textit{continuos} e $iid$, si $n$ es grande, puede aproximarse por una Gumbel, una Fréchet o una Weibull. Una aproximación será válida dependiendo de la distribución de $F$. En este sentido, cuando $F$ sea normal entonces $F_n^*$ se puede aproximar como una Gumbel. Cuando $F$ sea uniforme, se puede aproximar $F_n^*$ como una Weibull y cuando $F$ sea Cauchy entonces $F_n^*$ se puede aproximar por una Fréchet. 

Más precisamente, cuál de las tres aproximaciones es la aplicable depende de la cola de $F$ (los valores de $F(t)$ para valores grandes de $t$).
En concreto, Weibull aparece cuando $F$ es la distribución de una variable acotada por arriba (como la Uniforme), Gumbel para distribuciones de variables no acotadas por arriba pero con colas muy livianas (caso Exponencial y Normal) y Fréchet para colas pesadas (caso Cauchy)\footnote{Si bien  la hipótesis de continuidad de $F$ no es esencial, si $F$ tiene
la distribución Binomial o Poisson, por ejemplo, no se puede aplicar ninguna de las tres aproximaciones anteriores.}.

Como consecuencia del $FTG$ cuando se tengan datos máximos, las distribuciones maximales podrían ser candidatas de uno de los ajustes si

\begin{itemize}
\item la cantidad de registros es lo suficientemente grande
\item los registros son $iid$ aunque con versiones más generales del $FTG$ este supuesto puede no cumplirse
\end{itemize}

Como la mayoría de tests de ajustes suponen datos $iid$, se van a realizar dos tests de aleatoriedad\footnote{En inglés se expresa como \textit{randomness}} a los datos:

\begin{itemize}
\item  Runs up and down 
\item  Spearman correlation of ranks 
\end{itemize}

Se emplea la prueba de ajuste $\chi^2$ que requiere seleccionar una partición más o menos arbitraria de la recta real de intervalos siendo importante que en cada intervalo haya una cantidad lo suficientemente importante de datos de la muestra. En este sentido, se pueden tomar como extremos de los intervalos los quintiles empíricos de la muestra. Cabe mencionar que este test requiere estimar parámetros por el método de Máxia Verosimilitud Categórica.

Cabe mencionar que para este estudio la distribución de la variable a incorporar en este estudio no tiene que ser degenerada, es decir $H(t)=0$ ó $H(t)=1$.

\newpage

### Definición 2: Distribución extremal asintótica

Si $X_1,...,X_n$  es $iid$ con distribución $F$ diremos que $H$ no-degenerada es la Distribución Extremal Asintótica (DEA) de $F$\footnote{Lo que equivale a decir que $F$ tiene $DEA\;H$.}, si existen dos sucesiones de números reales, $d_n$ y $c_n>0$, tales que la distribución de

\begin{equation}
\frac{max(X_1,...,X_n)- d_n}{c_n}\label{eq:max}
\end{equation}

tiende a $H$ cuando $n$ tiende a infinito.


### Definición 3: Supremo esencial de una variable aleatoria o distribución

Si $X$ tiene distribución $F$, se llama supremo esencial de $X$, denotado como $M_X$ o, indistintamente, supremo esencial de $F$, denotado $MF$ a

\begin{equation}
M_X=M_F= sup\{t / F(t)<1\}\label{eq:Mx}
\end{equation}

Observación:
\begin{itemize}
\item Si $F$ es $U(a,b)$, $M_F=b$
\item Si $F$ es $Bin(m,p)$, $M_F=m$
\item Si $F$ es Normal, Exponencial, Cauchy o Poisson, $M_F$ es infinito.
\end{itemize}

##### Teorema 4

Si $X_1,...,X_n$ es $iid$ con distribución $F$ cualquiera, entonces, para $n$ tendiendo a infinito,

\begin{equation}
X^*_n=M_F= max(X_1,...,X_n)\;tiende\;a\;M_F\label{eq:Xast}
\end{equation}

Observación:

El resultado anterior vale incluso si $M_F$ es infinito, pero si $M_F$ es finito, como $X^*n - M_F$ tiende a cero, por analogía con el Teorema Central del Límite para promedios, buscaríamos una sucesión $c_n>0$ y que tienda a cero de modo tal que $(X^*n- M_F )/ c_n$ tienda a una distribución no-degenerada y de allí surge buscar la DEA.


##### Teorema 5


Si $F$ es una distribución con $M_F$ finito, y para $X$ con distribución $F$ se cumple que

$$
P(X=M_F)>0 
$$

entonces $F$ NO admite DEA.

Observación:

Si $F$ es $Bin(m,p)$, $M_F=m$. Si $X$ tiene distribución $F$, entonces
$P( X=M_F)= P( X=m)= p_m>0$,
asi que la distribucion $Bin(m,p)$ NO admite DEA, no se puede aproximar la distribución del máximo de una muestra $iid$ de variables $Bin(m,p)$.

El Teorema anterior es un caso particular del próximo.


##### Teorema 6

Si $F$ es una distribución con $M_F$ finito o infinito que admite DEA, y $X$ tiene distribución $F$, entonces el límite cuando $t$ tiende a $M_F$ por izquierda de
$P(X>t)/P(X \geq t)$ debe ser 1.


Observación:

\begin{itemize}
\item Si $F$ es una distribución de Poisson de parámetro $\lambda>0$, $M_F$ es infinito. 
\item Si $k$ es un natural, entonces:
\begin{eqnarray}
\frac{P(X>k)}{P(X\geq k)} &=& \frac{P(X \geq k+1)}{P(X\geq k)} \\ \nonumber
&=& 1-\frac{P(X=k)}{P(X \geq k)} \approx 1-\left(1- \frac{\lambda}{k}\right) 
\end{eqnarray}
que tiende a $0$ cuando $k$ tiende a infinito, por lo cual $F$ NO admite DEA, o sea que no se puede aproximar el máximo de una sucesión $iid$ de variables de Poisson.
\end{itemize}

Observación:

El Teorema 6 brinda una condición NECESARIA pero NO SUFICIENTE para DEA. Un ejemplo de ello lo aportó Von Mises, mostrando que la distribución

$$F(x)= 1- e^{(-x-sen(x))}$$
cumple con la condicion del Teorema 6 pero no admite DEA.

### Definición 4: Distribución max-estables

Si dada una $F$ distribución, $X$ con distribución $F$, $k$ natural arbitrario y $X_1,...,X_k$ es $iid$ con distribución $F$, existen reales $a_k$, $b_k$ tales que $max(X_1,...,X_k)$ tiene la misma distribución que $a_k X+ b_k$, $F$ se dice \textit{max-estable}.

El Teorema FTG resulta de superponer los dos siguientes teoremas:

##### Teorema 7

\begin{itemize}
  \item[a)] Si $F$ admite $DEA\;H$, entonces $H$ es max-estable.
  \item[b)] Si $H$ es max-estable, es la DEA de sí misma.
\end{itemize}

##### Teorema 8

Una distribución es max-estable si y solo si es extremal\footnote{O sea Gumbel, Weibull o Fréchet}.
El Teorema 7 es bastante intuitivo y análogo a los teoremas de Lévy sobre distribuciones estables en aproximaciones asintóticas de las distribuciones de sumas. Para el Teorema 8 haremos enseguida un ejercicio sencillo que nos ayudará a hacerlo creíble.
Luego precisaremos, para terminar con esta parte, cómo son las distribuciones que tienen por DEA cada uno de los tres tipos de distribuciones extremales. Para eso precisamos recordar algunas definiciones, como la siguiente.


Obsrvación:

Si $F$ y $G$ son dos distribuciones, tienen colas equivalentes si $M_F=M_G$ y cuando $t$ tiende a $M_F$ por izquierda, $(1-F(t))/(1-G(t))$ tiende a un valor $c>0$.
Recordando ahora cómo se calcula la distribución del máximo de dos variables independientes, es muy sencillo calcular la distribución del $max\{X,Y\}$, cuando $X$ e $Y$ son independientes y cada una de ellas es una distribución extremal. 

Se tiene el siguiente resultado:

| $X$ | $Y$| $max(X,Y)$ |
|-------|-------|--------------|
| \textcolor{red}{Weibull} | \textcolor{red}{Weibull} | \textcolor{red}{Weibull} |
| \textcolor[rgb]{0.0,0.5,0.0}{Weibull} | \textcolor[rgb]{0.0,0.5,0.0}{Gumbel} | \textcolor[rgb]{0.0,0.5,0.0}{Cola equivalente Gumbel} |
| \textcolor{blue}{Weibull} | \textcolor{blue}{Fréchet} | \textcolor{blue}{Fréchet} |
| \textcolor[rgb]{0.0,0.5,0.0}{Gumbel} | \textcolor[rgb]{0.0,0.5,0.0}{Weibull} | \textcolor[rgb]{0.0,0.5,0.0}{Cola equivalente Gumbel} |
| \textcolor{red}{Gumbel} | \textcolor{red}{Gumbel} | \textcolor{red}{Gumbel} |
| \textcolor{blue}{Gumbel} | \textcolor{blue}{Fréchet} | \textcolor{blue}{Cola equivalente Fréchet} |
| \textcolor{blue}{Fréchet} | \textcolor{blue}{Weibull} | \textcolor{blue}{Fréchet} |
| \textcolor{blue}{Fréchet} | \textcolor{blue}{Gumbel} | \textcolor{blue}{Cola equivalente Fréchet} |
| \textcolor{red}{Fréchet} | \textcolor{red}{Fréchet}| \textcolor{red}{Fréchet} |


\textcolor{red}{\rule{1em}{1em} Las extremales son max-estables: tomar máximos de dos del mismo tipo queda en el mismo tipo.}


\textcolor[rgb]{0.0,0.5,0.0}{\rule{1em}{1em} Gumbel es más pesada que Weibull. En la cola, que es lo que cuenta para máximos, prima Gumbel.}


\textcolor{blue}{\rule{1em}{1em} Fréchet es más pesada que Gumbel y mucho más pesada que Weibull.}
\vspace{1cm}

Además, de la tabla se deduce que 

##### Teorema 9 

Si $X_1,...,X_n$ independientes y cada $X_i$ tiene uno de los tres tipos de distribución extremal, entonces la distribución del $max(X_1,...,X_n)$ es:
\begin{itemize}
\item[a)] Cola equivalente a Fréchet, si alguna de las variables es Fréchet y alguna otra es Gumbel.
\item[b)]  Fréchet, si alguna es Fréchet y ninguna es Gumbel.
\item[c)]  Cola equivalente Gumbel ninguna es Fréchet pero algunas son Gumbel y otras Weibull.
\item[d)] Gumbel si todas son Gumbel.
\item[e)]  Weibull si todas son Weibull.
\end{itemize}

Observación:

Si $F$ es una distribución, se dice que tiene \textit{cola de variación regular de orden} $-\alpha$, para $\alpha \geq 0$, si para todo $t>0$, $(1-F(tx))/(1-F(x))$ tiende
a $t^{-\alpha}$ si $x \rightarrow  \infty$. Para abreviar se dirá que $F$ es $R_{-\alpha}$. Por ejemplo, para $\alpha=3$, un caso de una tal $F$ es $F(u)=1- 1/u^3$.


Por otra parte se dice que $L$ es una \textit{función de variación lenta} si, para todo $t>0$, $L(tx)/L(x)$ tiende a 1 cuando $x \rightarrow  \infty$. Por ejemplo, $L(u)=log(u)$.

\newpage

### Definición 4: Dominio de atracción maximal

Si $H$ es una distribución extremal (Gumbel, Weibull o Fréchet) su Dominio de Atracción Maximal ($DAM(H)$) está constituído por todas las distribuciones $F$ que tienen $DEA\;H$.

##### Teorema 9: DAM de la Fréchet

$F$ pertenece a la DAM de $\Phi_{\alpha}$ si y sólo si
$1-F(x)=x-\alpha L(x)$ para alguna $L$ de variación lenta,
lo cual es equivalente a decir que $F$ es $R_{-\alpha}$.


##### Corolario 1: DAM de la Fréchet
Si $F$ es una distribución con densidad $f$ que cumple que $xf(x)/(1-F(x))$ tiende a $\alpha$ cuando $x \rightarrow  \infty$
se dice que $F$ cumple la Condición de Von Mises I. En tal caso, $F$ pertenece a la DAM de $\Phi_{\alpha}$ y mas aún, la DAM de $\Phi_{\alpha}$ son todas las distribuciones que tienen cola equivalente a alguna distribución que cumpla la Condición de Von Mises I.
Del DAM Fréchet y Teorema 1, surge lo siguiente.


##### Teorema 10: DAM de la Weibull
\begin{itemize}
\item [a)] $F$ pertenece a la DAM de $\Psi_{\alpha}$ si y solo si $M_F$ es finito y además $$1-F(M_F -1/x)=x^{-\alpha} L(x)$$ para alguna
$L$ de variación lenta, es decir que pertenece a $R_{-\alpha}$. Observar que con el cambio de variable $u=M_F -1/x$,
resulta que $1-F(u)=(^{-}MF -u)^{\alpha} L(1/(M_F -u))$ para alguna $L$ de variación lenta, para $u< M_F$. Además puede tomarse $d_n= M_F$ y $c_n= n-\alpha$.
\item [b)] Si $F$ distribución con densidad $f$ positiva en $(a,M_F)$ para algun $a< M_F$ y $(M_F -x)f(x)/(1-F(x))$ tiende a $\alpha$ cuando $x\rightarrow M_F$, se dice que $F$ cumple la Condición de Von Mises II. En tal caso $F$ pertenece a la DAM de $\Psi_{\alpha}$ y mas aún, la DAM de $\Psi_{\alpha}$ son todas las distribuciones que tienen cola equivalente a alguna distribución que cumpla la Condición de Von Mises II.
\end{itemize}


\newpage

# Referencias bibliográficas
\vspace{1cm}
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}


