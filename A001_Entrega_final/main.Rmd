---
title: "Entrega: curso de datos extremales"
author: "Laura Montaldo, CI: 3.512.962-7"
date: "`r Sys.Date()`"
bibliography: references.bib  # Add this line
nocite: '@*'
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    includes:
      in_header: header2.tex
documentclass: article
classoption: oneside
lang: es
header-includes:
  - \usepackage{amsthm}
---

\newtheorem{theorem}{Teorema}[section]

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
rm(list = ls())
```




```{r include=FALSE}
library(patchwork)
if (!require(patchwork)) {
    install.packages("patchwork")
}
library(evd)
if (!require(evd)) {
    install.packages("evd")
}
if (!require(lubridate)) {
    install.packages("lubridate")
}
library(lubridate)
if (!require(dplyr)) {
    install.packages("dplyr")
}
library(dplyr)
if (!require(ggplot2)) {
    install.packages("ggplot2")
}
library(ggplot2)
if (!require(urca)) {
    install.packages("urca")
}
library(tseries)
if (!require(tseries)) {
    install.packages(tseries)
}
```
\newpage

<!-- titulo-->

\thispagestyle{empty}

\maketitle

\newpage

<!-- indice -->

\tableofcontents

\newpage

<!-- abstract -->

# Resumen

Your abstract goes here.

\newpage




```{r include=FALSE}
df = read.csv('../data/sp500_Closing_values.csv')
```


```{r include=FALSE}
head(df)
```


```{r include=FALSE}
# Convert the column to datetime format
df$Date <- ymd_hms(df$Date)
# Extract just the date part
df$Date <- as.Date(df$Date)
```

```{r include=FALSE}
head(df)
```


```{r include=FALSE}
str(df)
```


```{r include=FALSE}
# Create a new column 'relacion' with yesterday's price over today's price
df <- df %>%
  mutate(relacion = lag(Close) / Close)
```


```{r include=FALSE}
head(df)
```


<!-- MOTIVACION Y OBJETIVO DEL ESTUDIO -->


\section{Motivación y objetivo del estudio} 

<!-- introduccion a eventos raros -->

Siguiendo a @notas_curso, se dice que tenemos datos extremos cuando cada dato corresponde al máximo o mínimo de varios registros. Son un caso particular de evento raro o gran desviación respecto a la media. Entonces, en una gran variedad de dominios disciplinares suele ser de gran interés el trabajo con datos extremos, los que admiten diversos enfoques. La teoría más clásica de estadística de datos extremos se basa en los trabajos de Fréchet, Gumbel, Weibull, Fisher, Tippett, Gnedenko, entre otros. En este estudio, el foco va a estar puesto en esquemas que extienden a las distribuciones extremales clásicas.

<!-- indice -->

Los índices de $S\&P$ son una familia de índices de renta variable\footnote{En inglés se llaman equity indices} diseñados para medir el rendimiento del mercado de acciones en Estados Unidos que cotizan en bolsas estadounidenses. Ésta familia de índices está compuesta por una amplia variedad de índices basados en tamaño, sector y estilo. Los índices están ponderados por el criterio \textit{float-adjusted market capitalization} (FMC). Además, se disponen de índices ponderados de manera equitativa y con límite de capitalización de mercado, como es el caso del $S\&P\:500$. Este este sentido, el $S\&P 500$ entraría en el conjunto de índices ponderados por capitalización bursátil ajustada a la flotación (ver \href{http://www.overleaf.com}{\textcolor{blue}{$S\&P$ Dow Jones Indices}}). El mismo  mide el rendimiento del segmento de gran capitalización del mercado estadounidense. Es considerado como un indicador representativo del mercado de renta variable de los Estados Unidos, y está compuesto por 500 empresas constituyentes.
 
Se busca crear un indicador de una posible crisis bursátil. Como variable de referencia de toma la relación de precios al cierre de ayer sobre la de hoy 

\begin{equation}
Indicador_t=\frac{Precio_{t-1}}{Precio_t},\quad\text{para}\; t=1,...,T \label{eq:ind}
\end{equation}
\vspace{0.5cm}

Interpretación del Indicador:

\begin{itemize}
\item Si el $Indicador_t$    $\leq$ 1, el precio de cierre de hoy es mayor o igual que el de ayer, lo cual podría ser considerado una señal positiva.
\item Si el $Indicador_t$ > 1, el precio de cierre de hoy es menor que el de ayer, lo cual podría considerarse una señal de alerta.
\end{itemize}

\vspace{1cm}

```{r include=FALSE}
# Remove the first row
df <- df[-1, ]
```

\newpage

En las siguiente figuras se muestra la evolución histórica desde la fecha 03/01/1928 hasta 08/12/2023 del precio al cierre del día del indicar S&P 500.

```{r echo=FALSE}
# Check for any NA or non-finite values in Date or Close
df <- na.omit(df)

# Determine the range of dates
date_range <- range(df$Date, na.rm = TRUE)
```

```{r,label='plot1',echo=FALSE, r,label='plot1'}
# Your ggplot code
ggplot(df, aes(x = Date, y = Close)) +
  geom_line() +
  ggtitle("S&P500: valores diarios históricos al cierre (03/01/1928-08/12/2023)") +
  xlab("fecha") +
  ylab("Precio de cierre") +
  scale_x_date(limits = date_range) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11)  # Adjust the size parameter as needed
  )
```
```{r echo=FALSE}
dim(df)
```


```{r echo=FALSE}
ggplot(df, aes(x = Date, y = relacion)) +
  geom_line() +
  ggtitle("S&P500: Valores históricos del Indicador (03/01/1928-08/12/2023)") +
  xlab("Fecha") +
  ylab("Valores del Indicador") +
  scale_x_date(limits = date_range) +
  scale_y_continuous(breaks = seq(0, ceiling(max(df$relacion)), by = 0.05)) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11, hjust = 0.5),  # Center the plot title
    axis.text = element_text(size = 10),  # Adjust the size of axis text
    axis.title = element_text(size = 12),  # Adjust the size of axis titles
    legend.title = element_text(size = 10),  # Adjust the size of legend title
    legend.text = element_text(size = 8)  # Adjust the size of legend text
  )
```




```{r}
ts_relacion=df[,c('relacion')]
```



```{r}
result_adf <- suppressWarnings(adf.test(ts_relacion))
cat('p-valor adf:', result_adf$p.value ,'\n')
```



```{r}
result_kpss <- suppressWarnings(kpss.test(ts_relacion))
cat('p-valor kpss:', result_kpss$p.value ,'\n')
```

```{r}
#install.packages('aTSA')
aTSA::adf.test(ts_relacion)
```




<!-- MARCO TEORICO -->

\newpage

\section{Marco teorico}
\subsection{El enfoque de conteo de eventos y los modelos de base Poissoniana.} 

Fijaremos un cierto umbral, llamaremos \textit{evento} cuando la variable observada supera ese umbral y dado un cierto intervalo del tiempo $J$, contaremos

\begin{eqution}
N(J)= \text{número de eventos en el intervalo}\; J.
\end{equation}


Fijando un $u=1.025$, el evento es una señal negativa del precio de $SP\$500$ que estaría dado por la cantidad de días en el mes $J$ que $Indicador_t$ supera el umbral $u$.
Un evento ser que $Indicador_t$ supere un umbral $u>1.025$.  Si el número de eventos está dado por los días de un mes, entonces $N(mes)$ va a ser la cantidad de días que occurió el evento en un mes, $N(mes)=3$ es la cantidad de señales negativas en el mes.

como la cantidad de días ($d$) que el indicar aumentó un cierto porcentaje de $d-1$ a $d$.

$2.5\%$ en un
Si $d$ es la cantidad de días y $J$ es el intervalo de días en un mes, N(mes)
N(mes)= cantidad de períodos de 3 días durante un mes, en que se registró una aumento mayor o igual a 2.5% del índice de un día para el otro.


$N$ es lo que se llama un proceso de conteo o proceso puntua\footnote{\textit{Counting process, Point process} en inglés}, un tipo de modelos utilizados en Logística, Telecomunicaciones, estudios de Contaminación Atmosférica o Costera, Clima, etc.

El proceso de conteo más simple es el llamado \textit{Proceso de Poisson}, que puede caracterizarse de la siguiente manera.


 
\begin{definition}[Proceso de Poisson]\label{def:1}
Si $N$ es un proceso de conteo y $\lambda>0$, diremos que $N$ es un Proceso de Poisson de parámetro $\lambda$ (y abreviaremos $N$ es $PP(\lambda)$ ) si se cumple:
\begin{itemize}
\item[a)] Para todo intervalo $J$ de los reales positivos, $N(J)$ es una variable aleatoria que tiene distribución de Poisson de parámetro $\lambda$ longitud($J$).
\item[b)] Si $J, L, M...$ es una cantidad arbitraria de intervalos de reales positivos \textit{disjuntos}, entonces $N(J), N(L), N(M),...$ son variables aleatorias independientes.
\end{itemize}
\end{definition}

El siguiente teorema brinda una visualización muy interesante de los Procesos de Poisson, que nos servirá mucho para introducir otros modelos y que es ideal para poder simular computacionalmente Procesos de Poissson.

\begin{theorem}[Otra visión de los Procesos de Poisson]\label{thm:otra_vision}
Si $T_1,...,T_n,...$ se supone $iid$,  con distribución Exponencial de parámetro $\lambda>0$ y definimos que ocurre el primer evento en el instante $T_1$, el segundo en el instante $T_1+T_2$, el tercero en el instante $T_1+T_2+T_3$ y asì sucesivamente, el proceso $N$ de conteo de tales eventos, es un proceso de Poisson.
\end{theorem}




Dicho de otro modo el Proceso de Poisson representa eventos aislados ("que ocurren de a uno y claramente separados"), con tiempos inter-eventos $iid$ y exponenciales.
Obviamente, esto muchas veces es \textit{too good to be true}, pero variaciones de este modelo tan simple pueden brindar modelos realistas.


##### Observación 1: 

En la práctica, si se toman datos en los instantes $1,...,n$ suele reescalarse el tiempo dividiendo por $n$ y los instantes quedan en $[0,1]$. Allí se define un $PP$ de manera casi idéntica, obviamente modificando en la definición, tanto en $a)$ como en $b)$ que los intervalos deben estar contenidos en $[0,1]$.

##### Observación 2: 

Conviene recordar que si $X$ es una $VA$ Poisson de parámetro $\lambda>0$ y $T$ es una $VA$ exponencial de parámetro $\lambda$, entonces $E(X)= \lambda$ y $E(T)=1/lambda$ . Si $T_1,...,T_n,...$ siendo $iid$ son los tiempos inter-eventos de un $PP(\lambda)$ se deduce entonces de la ley de los grandes números que

\begin{equation}
\frac{\sum_{i=1}^{i=n} T_i}{n} \rightarrow 1/ \lambda \quad cuando \quad n\rightarrow \infty
\end{equation}

Es decir que el tiempo promedio entre eventos "a la larga" es $1/\lambda$ . Similarmente si $J_1,...,J_n,...$ son intervalos disjuntos de longitud $1$, por la definición \ref{def:1} y la ley de los grandes números se tiene que


\begin{equation}
\frac{\sum_{i=1}^{i=n} N(J_i)}{n} \rightarrow \lambda \quad cuando \quad n\rightarrow \infty
\end{equation}

Más aún, puede probarse que

\begin{equation}
\frac{N((0,t))}{t} \rightarrow \lambda \quad cuando \quad t \rightarrow \infty
\end{equation}

Esto permite observar una consecuencia del Teorema \ref{thm:otra_vision}, que es una propiedad intuitivamente muy atractiva.

La tasa promedial de incidencia de los eventos en un $PP(\lambda)$ es inversamente proporcional al tiempo promedial inter-eventos.

##### Ejemplo 1: 

Propiedades como esta hicieron, en las primeras dos décadas del siglo $XX$, a un creador genial como Agner Erlang modelar mediante Procesos de Poisson las llamadas que arribaban a una central telefónica, así como (con parámetros muy distintos) el proceso de ocupación de las líneas entre dos centrales. Eso condujo no sólo al desarrollo de las primeras centrales de telefonía conmutada por circuitos por CTC, la filial danesa de Bell, sino además a que Erlang desarrollara su "fórmulas de bloqueo", fino cálculo por el cual, según los parámetros del proceso de arribo y del proceso de ocupación de líneas, se calcula la probabilidad de "saturación" (no hay ninguna línea disponible) dado el número de líneas entre centrales, o, dada una probabilidad de saturación “tolerable” ($\epsilon$).

DISEÑAR (determinar el mínimo número de lineas necesarias para que la probabilidad de bloqueo no exceda $\epsilon$ ). Si el tiempo entre arribos de llamadas a la central es Exponencial de parámetro $\lambda$, y la duración media de una llamada es Exponencial de parámetro $\mu$, entonces el parámetro crucial de la fórmula de Erlang es 

\begin{align}
\rho=&\lambda/\mu  \nonumber \\
= &\text{“duración media de la llamada”/ “tiempo medio entre llamadas”}\label{eq:ro}
\end{align}


y a mayor valor de $\rho$, mayor probabilidad de saturación para una conectividad dada. Esta fórmula  \eqref{eq:ro} aún sigue en uso en algunos problemas y dió pie al desarrollo de fórmulas de bloqueo más sofisticadas para situaciones más complejas. Con mucha justicia, la unidad en la que se mide la intensidad de tráfico en redes se llama \textit{erlang} y este ejemplo nos parece una clara muestra de cuán útil ha sido el muy sencillo Proceso de Poisson.
Sin embargo, en otros problemas, por ejemplo en modernas redes de datos en las que los “eventos” de “demanda de servicio” pueden ocurrir simultáneamente en muy grandes cantidades (“clustering”), aparece un modelo más sofisticado, que puede ser definido a partir del Proceso de Poisson: el Proceso de Poisson Compuesto.


\begin{definition}[Proceso de Poisson Compuesto]\label{def:2}
Si $N$ es un Proceso de Poisson de parámetro $\lambda>0$ , $G$ es una distribución de probabilidad en los naturales $1,2,3...$, consideramos un proceso $S_1,...,S_n$ $iid$ con distribución $G$ y construímos un nuevo proceso de conteo $M$ de la forma siguiente:
\begin{itemize}
\item Cuando $N$ tiene su primer evento, $M$ tiene $S_1$ eventos simultáneos;
\item Cuando $N$ tiene su segundo evento, $M$ tiene $S_2$ eventos simultáneos..... (y así sucesivamente)
\end{itemize}
decimos que $M$ es un Proceso de Poisson Compuesto de parámetro $\lambda>0$ y distribución de eventos $G$ (y abreviaremos $M$ es $PPC(\lambda;G)$)
\end{definition}


##### Ejercicio 1 : 

Demostrar que para un $PPC(\lambda;G)$ el tiempo medio inter-eventos sigue siendo $1/\lambda$, pero que la tasa de incidencia media de eventos ahora es $lambda E(G)$.



##### Observación 3. 

Para aclarar, si $G$ es una distribución degenerada otorga al 1 probabilidad 1, el correspondiente $PPC(\lambda;G)$ en realidad es un $PPC(\lambda)$. Ergo, el $PP$ es un caso particular de $PPC$.

##### Observación 4. 

Para evitar confusiones frecuentes, distinguiremos explícitamente estos procesos de los llamados Procesos de Poisson no-homogéneos. Para ello recordemos, sin entrar en tecnicismos, que una medida en los reales positivos es una función que a los conjuntos asocia números positivos con las mismas propiedades formales, excepto que no tiene por qué dar a todo el conjunto de los reales positivos ( a todo el universo) el valor 1. Dicho de otro modo una probabilidad es una medida particular, que a todo el universo asigna el valor 1. Puede pensarse como ejemplo típico de una medida, la que asigna a un conjunto la integral sobre ese conjunto de una función no negativa (no necesariamente de integral total 1, puede ser incluso infinita). La longitud es el ejemplo más simple de medida (llamada también medida de Lebesgue) y la longitud de todos los reales positivos es infinito. Puede demostrarse que la longitud multiplicada por una constante no negativa son las únicas medidas invariantes por traslaciones, punto importante para la distinción que queremos hacer.

\begin{definition}[Proceso de Poisson No Homogéneo]\label{def:3}
Si $N$ es un proceso de conteo y $m$ es una medida que NO puede expresarse como una constante por la longitud, diremos que $N$ es un Proceso de Poisson No Homogéneo de medida $m$ (y abreviaremos $N$ es $PPNH(m)$ ) si se cumple:

\begin{itemize}
\item[a)] Para todo intervalo $J$ de los reales positivos, $N(J)$ es una variable aleatoria que tiene distribución de Poisson de parámetro $m(J)$.
\item[b)] Si $J, L, M...$ es una cantidad arbitraria de intervalos positivos DISJUNTOS, entonces $N(J), N(L), N(M),...$ son variables aleatorias independientes.
\end{itemize}
\end{definition}

Queda claro que el proceso de Poisson podría verse de la manera a) y b) anterior cuando $m=\text{constante por longitud}$, por eso, para no confundir, se excluye a título expreso que $m$ pueda ser constante por longitud.
Para dejar en claro la diferencia entre los PPNH y los PPC ( o el simple PP), recordemos que en los PPC, los tiempos inter-eventos son exponenciales de parámetro $\lambda>0$ e $iid$. El siguiente resultado muestra la diferencia de conceptos. Por su extrema simplicidad, lo detallaremos.


\begin{theorem}[PPNH no es PPC]\label{thm:2}
Si $N$ es un PPNH y $T_1$ es el tiempo del primer evento, la distribución de $T_1$ no es exponencial.
Por lo tanto, un PPNH no es PPC.
\end{theorem}

##### Demostración:

$$
P(T_1\le t)=P(N((0,t))\ge 1)=1-P(N((0,t))=0)= 1-e^{-m((0,t))}\quad\text{para todo}\; t>0.
$$


Si $T_1$ fuera exponencial, entonces para algún $\lambda>0$ y para todo $t>0$ sería:


$m((0,t))= \lambda t$ y por ende, si $a <b$ cualquiera,

$$m((a,b))= m((0,b))-m((0,a))=\lambda b- \lambda a= \lambda(b-a)=\lambda x\;longitud((a,b))$$ 

por lo cual se concluye, $m=\lambda x\:longitud$


lo cual es absurdo $\blacklozenge$.


<!-- ME QUEDE EN PAGINA 72 DEMOSTRACION-->


<!-- MT:  Peaks Over Treshold) y variantes-->

\newpage


\subsection{POT (Peaks Over Treshold) y variantes}



<!-- ESTRATEGIA EMPIRICA -->


\newpage
\section{Estrategia Empírica}



A la columna relativa a la relacion de precios se la resta por 1 para tener centrados los valores de la relacion de precios en cero. Y posteriormente analizar si las series, fijando distintos umbrales son estacionarias.

```{r echo=FALSE}
df$rel_cero=df$relacion-1
```

```{r echo=FALSE}
datos_filtrados <- df %>% 
  filter(rel_cero >= 0)
```


```{r echo=FALSE}
datos=datos_filtrados[,c('Date', 'rel_cero')]
```




```{r echo=FALSE}
ggplot(datos, aes(x = Date, y = rel_cero)) +
  geom_line() +
  ggtitle("Valores del indicador centrado en cero, mayores o iguales a cero") +
  xlab("Fecha") +
  ylab("Valores del Indicador") +
  scale_x_date(limits = date_range) +
  scale_y_continuous(breaks = seq(0, ceiling(max(df$relacion)), by = 0.05)) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11, hjust = 0.5),  # Center the plot title
    axis.text = element_text(size = 10),  # Adjust the size of axis text
    axis.title = element_text(size = 12),  # Adjust the size of axis titles
    legend.title = element_text(size = 10),  # Adjust the size of legend title
    legend.text = element_text(size = 8)  # Adjust the size of legend text
  )
```



```{r echo=FALSE}
ggplot(datos, aes(x = Date, y = rel_cero)) +
  geom_line() +
  geom_hline(yintercept = 0.025, linetype = "solid", color = "purple") +  # Add horizontal line
  ggtitle("Indicador centrado con umbral de 0.015") +
  xlab("Fecha") +
  ylab("Valores del Indicador") +
  scale_x_date(limits = date_range) +
  scale_y_continuous(breaks = seq(0, ceiling(max(df$relacion)), by = 0.05)) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11, hjust = 0.5),  # Center the plot title
    axis.text = element_text(size = 10),  # Adjust the size of axis text
    axis.title = element_text(size = 12),  # Adjust the size of axis titles
    legend.title = element_text(size = 10),  # Adjust the size of legend title
    legend.text = element_text(size = 8)  # Adjust the size of legend text
  )

```



```{r echo=FALSE}
ggplot(datos, aes(x = Date, y = rel_cero)) +
  geom_line() +
  geom_hline(yintercept = 0.025, linetype = "solid", color = "red") +  # Add horizontal line
  ggtitle("Indicador centrado con umbral de 0.025") +
  xlab("Fecha") +
  ylab("Valores del Indicador") +
  scale_x_date(limits = date_range) +
  scale_y_continuous(breaks = seq(0, ceiling(max(df$relacion)), by = 0.05)) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11, hjust = 0.5),  # Center the plot title
    axis.text = element_text(size = 10),  # Adjust the size of axis text
    axis.title = element_text(size = 12),  # Adjust the size of axis titles
    legend.title = element_text(size = 10),  # Adjust the size of legend title
    legend.text = element_text(size = 8)  # Adjust the size of legend text
  )
```

```{r echo=FALSE}

ggplot(datos, aes(x = Date, y = rel_cero)) +
  geom_line() +
  geom_hline(yintercept = 0.05, linetype = "solid", color = "cyan") +  # Add horizontal line
  ggtitle("Indicador centrado con umbral de 0.05") +
  xlab("Fecha") +
  ylab("Valores del Indicador") +
  scale_x_date(limits = date_range) +
  scale_y_continuous(breaks = seq(0, ceiling(max(df$relacion)), by = 0.05)) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11, hjust = 0.5),  # Center the plot title
    axis.text = element_text(size = 10),  # Adjust the size of axis text
    axis.title = element_text(size = 12),  # Adjust the size of axis titles
    legend.title = element_text(size = 10),  # Adjust the size of legend title
    legend.text = element_text(size = 8)  # Adjust the size of legend text
  )
```


```{r}
filtered_df_0_025 <- df %>%
  filter(rel_cero>= 0.025)
```


```{r}
head(filtered_df_0_025)
data=filtered_df_0_025[,c('Date', 'rel_cero')]
n=dim(data)[1]
```


```{r}
fecha_maxima <- max(data$Date)
# Reescalar el tiempo dividiendo cada fecha por la fecha máxima
data$tiempo_reescalado <- as.numeric(data$Date - min(data$Date)) / as.numeric(fecha_maxima - min(data$Date))
head(data)
```



```{r}
ggplot(df, aes(x = Date, y = rel_cero)) +
  geom_line() +
  geom_hline(yintercept = 0.05, linetype = "solid", color = "cyan") +  # Add horizontal line
  ggtitle("S&P500: Valores históricos del Indicador (03/01/1928-08/12/2023)") +
  xlab("Fecha") +
  ylab("Valores del Indicador") +
  scale_x_date(limits = date_range) +
  scale_y_continuous(breaks = seq(0, ceiling(max(df$relacion)), by = 0.05)) +
  theme(
    axis.title.x = element_text(margin = margin(t = 20, b = 40)),
    axis.title.y = element_text(margin = margin(r = 20, l = 40)),
    plot.title = element_text(size = 11, hjust = 0.5),  # Center the plot title
    axis.text = element_text(size = 10),  # Adjust the size of axis text
    axis.title = element_text(size = 12),  # Adjust the size of axis titles
    legend.title = element_text(size = 10),  # Adjust the size of legend title
    legend.text = element_text(size = 8)  # Adjust the size of legend text
  )
```


```{r}
filtered_df_0_05 <- df %>%
  filter(rel_cero >= 0.05)
dim(filtered_df_0_05)
```

```{r}
plot(filtered_df_0_05)
```


```{r}
hist(filtered_df_0_05$relacion, main = "Histograma relacion con umbral 0.05 ", xlab = "relacion")
```
```{r}
hist(filtered_df_0_025$relacion, main = "Histograma relacion con umbral 0.025 ", xlab = "relacion")
```






